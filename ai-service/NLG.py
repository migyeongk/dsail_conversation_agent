# NLG.py - Natural Language Generation
import time
from logger_config import ai_logger, log_api_call, log_error
from prompts import (
    MULTI_POLICY_BASE_PROMPT, 
    POLICY_PROMPTS_SINGLE, 
    POLICY_MAX_TOKENS,
    POLICY_PROMPTS_MULTI,
    TONE_PROMPTS
)

def generate_response(policy, user_message, history, status, client, tone_preference=None):
    """ì •ì±…ì— ë”°ë¼ ì‘ë‹µì„ ìƒì„±í•˜ë„ë¡ ìš”ì²­í•˜ëŠ” ë©”ì¸ í•¨ìˆ˜"""
    ai_logger.info("ğŸ¤– ì‘ë‹µ ìƒì„± ì¤‘...")
    second_policy = policy.get('second_policy', 'default')

    if second_policy == None:
        response = generate_response_by_policy(policy, user_message, history, status, client, tone_preference)
        return response
    else:
        response = generate_response_by_policies(policy, user_message, history, status, client, tone_preference)
        return response


def generate_response_by_policy(policy, user_message, history, status, client, tone_preference=None):
    """í†µí•©ëœ ì‘ë‹µ ìƒì„± í•¨ìˆ˜ - ëª¨ë“  ì •ì±…ì— ëŒ€í•´ ë™ì¼í•œ ë¡œì§ ì‚¬ìš©"""
    ai_logger.info("ğŸ” í•œ ê°œì˜ ì‘ë‹µ ì •ì±…ì„ ì¡°í•©í•˜ì—¬ ìµœì¢… ì‘ë‹µì„ ìƒì„±")
    
    first_policy = policy.get('first_policy', 'default')
    ai_logger.info(f"ğŸ” ì„ íƒëœ ì •ì±…: {first_policy}")
    
    prompt = POLICY_PROMPTS_SINGLE.get(first_policy, "announce_completion")
    question = check_question(policy)
    
    # ë§íˆ¬ í”„ë¡¬í”„íŠ¸ ì¶”ê°€
    tone_prompt = TONE_PROMPTS.get(tone_preference or 'ë¯¸ì„ íƒ', TONE_PROMPTS['ë¯¸ì„ íƒ'])
    ai_logger.info(f"ğŸ” ì„ íƒëœ ë§íˆ¬: {tone_preference}")
    prompt_with_tone = prompt + "\n" + tone_prompt

    if question != None:
        context_history = f"ì„ íƒëœ ì •ì±…: {policy}\nëŒ€í™” íˆìŠ¤í† ë¦¬:\n{history}\ní˜„ì¬ ì‚¬ìš©ì ë©”ì‹œì§€: {user_message}\ní˜„ì¬ ë¬¸ì§„ ìƒíƒœ: {status}\nì„ íƒëœ ë¬¸ì§„ë¬¸í•­: {question}"
    else:
        context_history = f"ì„ íƒëœ ì •ì±…: {policy}\nëŒ€í™” íˆìŠ¤í† ë¦¬:\n{history}\ní˜„ì¬ ì‚¬ìš©ì ë©”ì‹œì§€: {user_message}\ní˜„ì¬ ë¬¸ì§„ ìƒíƒœ: {status}"

    messages = [
        {"role": "system", "content": prompt_with_tone},
        {"role": "user", "content": context_history}
    ]
    
    # ì •ì±…ë³„ í† í° ì œí•œ
    max_tokens = POLICY_MAX_TOKENS.get(first_policy,200)
    
    max_retries = 3
    retry_delay = 1  # ì´ˆ
    
    for attempt in range(max_retries):
        try:
            if attempt > 0:
                ai_logger.info(f"ğŸ”„ ì‘ë‹µ ìƒì„± ì¬ì‹œë„ {attempt}/{max_retries}")
                time.sleep(retry_delay * attempt)  # ì¬ì‹œë„ ì‹œ ëŒ€ê¸° ì‹œê°„ ì¦ê°€
            
            log_api_call("gpt-5-chat-latest", f"response_generation_{first_policy}", attempt + 1)
            # OpenAI API í˜¸ì¶œ
            response = client.chat.completions.create(
                model="gpt-5-chat-latest",
                messages=messages,
                max_tokens=max_tokens,
                temperature=0.7
            )
            
            generated_response = response.choices[0].message.content.strip()
            ai_logger.info(f"âœ… ì‘ë‹µ ìƒì„± ì™„ë£Œ: {generated_response}")
            return generated_response
            
        except Exception as e:
            ai_logger.warning(f"âš ï¸ ì‘ë‹µ ìƒì„± ì‹œë„ {attempt + 1} ì‹¤íŒ¨: {str(e)}")
            if attempt == max_retries - 1:
                log_error("ì‘ë‹µ ìƒì„± ìµœì¢… ì‹¤íŒ¨", e)
                return "ì£„ì†¡í•©ë‹ˆë‹¤. ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
            continue


def generate_response_by_policies(policy, user_message, history, status, client, tone_preference=None):
    """ë‘ ê°œì˜ ì‘ë‹µ ì •ì±…ì„ ì¡°í•©í•˜ì—¬ ìµœì¢… ì‘ë‹µì„ ìƒì„±í•˜ëŠ” í•¨ìˆ˜"""
    ai_logger.info("ğŸ” ë‘ ê°œì˜ ì‘ë‹µ ì •ì±…ì„ ì¡°í•©í•˜ì—¬ ìµœì¢… ì‘ë‹µì„ ìƒì„±")

    first_policy = policy.get('first_policy', '')
    second_policy = policy.get('second_policy', '')
    ai_logger.info(f"ğŸ” ì„ íƒëœ ì •ì±…ë“¤: {first_policy}, {second_policy}")
    
    # í•µì‹¬ ì§€ì‹œì‚¬í•­ë§Œ ì¡°í•©
    instruction_1 = POLICY_PROMPTS_MULTI.get(first_policy, "announce_completion")
    instruction_2 = POLICY_PROMPTS_MULTI.get(second_policy, "announce_completion")
    
    policy_instructions = f"ì •ì±… 1: {instruction_1}\nì •ì±… 2: {instruction_2}"
    combined_prompt = MULTI_POLICY_BASE_PROMPT.format(policy_instructions=policy_instructions)
    
    # ë§íˆ¬ í”„ë¡¬í”„íŠ¸ ì¶”ê°€
    tone_prompt = TONE_PROMPTS.get(tone_preference or 'ë¯¸ì„ íƒ', TONE_PROMPTS['ë¯¸ì„ íƒ'])
    ai_logger.info(f"ğŸ” ì„ íƒëœ ë§íˆ¬: {tone_preference}")
    combined_prompt_with_tone = combined_prompt + "\n" + tone_prompt
    
    question = check_question(policy)
    
    if question != None:
        context_history = f"ì„ íƒëœ ì •ì±…: {first_policy}, {second_policy}\nëŒ€í™” íˆìŠ¤í† ë¦¬:\n{history}\ní˜„ì¬ ì‚¬ìš©ì ë©”ì‹œì§€: {user_message}\ní˜„ì¬ ë¬¸ì§„ ìƒíƒœ: {status}\nì„ íƒëœ ë¬¸ì§„ë¬¸í•­: {question}"
    else:
        context_history = f"ì„ íƒëœ ì •ì±…: {first_policy}, {second_policy}\nëŒ€í™” íˆìŠ¤í† ë¦¬:\n{history}\ní˜„ì¬ ì‚¬ìš©ì ë©”ì‹œì§€: {user_message}\ní˜„ì¬ ë¬¸ì§„ ìƒíƒœ: {status}"
    
    messages = [
        {"role": "system", "content": combined_prompt_with_tone},
        {"role": "user", "content": context_history}
    ]

    
    max_retries = 3
    retry_delay = 1  # ì´ˆ
    
    for attempt in range(max_retries):
        try:
            if attempt > 0:
                ai_logger.info(f"ğŸ”„ ë³µí•© ì •ì±… ì‘ë‹µ ìƒì„± ì¬ì‹œë„ {attempt}/{max_retries}")
                time.sleep(retry_delay * attempt)  # ì¬ì‹œë„ ì‹œ ëŒ€ê¸° ì‹œê°„ ì¦ê°€
            
            log_api_call("gpt-5-chat-latest", f"response_generation_{first_policy}_{second_policy}", attempt + 1)
            response = client.chat.completions.create(
                model="gpt-5-chat-latest",
                messages=messages,
                max_tokens=300,
                temperature=0.7
            )
            
            generated_response = response.choices[0].message.content.strip()
            ai_logger.info(f"âœ… ë³µí•© ì •ì±… ì‘ë‹µ ìƒì„± ì™„ë£Œ: {generated_response}")
            return generated_response
            
        except Exception as e:
            ai_logger.warning(f"âš ï¸ ë³µí•© ì •ì±… ì‘ë‹µ ìƒì„± ì‹œë„ {attempt + 1} ì‹¤íŒ¨: {str(e)}")
            if attempt == max_retries - 1:
                log_error("ë³µí•© ì •ì±… ì‘ë‹µ ìƒì„± ìµœì¢… ì‹¤íŒ¨", e)
                return "ì£„ì†¡í•©ë‹ˆë‹¤. ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
            continue


def check_question(policy):
    """ì •ì±… ë”•ì…”ë„ˆë¦¬ì—ì„œ question ë¥¼ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜"""
    question = policy.get('next_question_text', None)
    ai_logger.info(f"ğŸ” ì„ íƒëœ ë¬¸ì§„ë¬¸í•­: {question}")
    return question